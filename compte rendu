# Compte Rendu Acad√©mique Complet : Pr√©diction de la Performance Scolaire

## Table des Mati√®res
1. [Introduction](#introduction)
2. [Analyse Exploratoire des Donn√©es (EDA)](#analyse-exploratoire-des-donn√©es-eda)
3. [M√©thodologie et Mod√©lisation](#m√©thodologie-et-mod√©lisation)
4. [R√©sultats et Comparaison des Mod√®les](#r√©sultats-et-comparaison-des-mod√®les)
5. [Recommandations](#recommandations)
6. [Conclusion](#conclusion)

---

## 1. Introduction

### Contexte du Projet
Le dataset **"Students Academic Performance"** analyse les facteurs influen√ßant la performance scolaire de **1000 √©tudiants am√©ricains**.

### Variables Analys√©es
Les variables incluent des facteurs :
- **Socio-d√©mographiques** : genre, origine ethnique, √©ducation parentale
- **Comportementaux** : type de d√©jeuner, pr√©paration aux tests
- **Acad√©miques** : scores en math√©matiques, lecture et √©criture (√©chelle 0-100)

### Objectif
Pr√©dire le niveau de performance en math√©matiques (Low/Medium/High) via des mod√®les de r√©gression et classification avanc√©s.

### Probl√©matique
Identifier les facteurs pr√©dictifs cl√©s et d√©velopper des mod√®les performants pour anticiper les difficult√©s scolaires.

---

## 2. Analyse Exploratoire des Donn√©es (EDA)

### 2.1 Chargement et Structure du Dataset

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('StudentsPerformance.csv')
print(f"Shape: {df.shape}")  # (1000, 8)
```

**Caract√©ristiques du dataset :**
- 1000 observations
- 8 variables
- Aucune donn√©e manquante (`df.isnull().sum() = 0`)
- Aucun doublon (`df.duplicated().sum() = 0`)

### 2.2 Pr√©traitement et Ing√©nierie des Caract√©ristiques

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
for col in ['gender', 'race/ethnicity', 'parental level of education', 
            'lunch', 'test preparation course']:
    df[col] = le.fit_transform(df[col])

# Cr√©ation des niveaux de performance
df['mathlevel'] = pd.cut(df['math score'], 
                         bins=[0,50,75,100], 
                         labels=['Low','Medium','High'])
df['mathlevelnum'] = df['mathlevel'].map({'Low':1, 'Medium':2, 'High':3})
```

### 2.3 Statistiques Descriptives

| Variable      | Moyenne | √âcart-type | Min | Max | M√©diane |
|---------------|---------|------------|-----|-----|---------|
| Math score    | 66.09   | 15.16      | 0   | 100 | 66      |
| Reading score | 69.17   | 14.60      | 17  | 100 | 70      |
| Writing score | 68.05   | 15.20      | 10  | 100 | 69      |

#### Observations Cl√©s
- Les √©tudiants affichent en moyenne de meilleures performances en **Lecture (69.17)** et en **√âcriture (68.05)** qu'en **Math√©matiques (66.09)**
- L'√©cart-type significatif (~15 points) indique une **grande variabilit√©** dans les performances
- Le score minimal de 0 en math√©matiques sugg√®re des cas de difficult√©s extr√™mes
- La m√©diane proche de la moyenne indique une distribution globalement sym√©trique

### 2.4 Analyses Statistiques et Visualisations

#### Corr√©lations
- **Corr√©lation minimale entre les scores : 0.80**
- Les trois scores acad√©miques sont extr√™mement corr√©l√©s entre eux
- **Lecture ‚Üî √âcriture : 0.95** (couple le plus fortement li√©)
- Cette interd√©pendance sugg√®re que les **facteurs d'apprentissage fondamentaux** sont plus d√©terminants que les connaissances sp√©cifiques √† chaque mati√®re

#### Distribution par Genre
- Distribution relativement √©quilibr√©e
- Tendance observ√©e : 
  - Femmes : meilleures performances en lecture et √©criture
  - Hommes : scores l√©g√®rement sup√©rieurs en math√©matiques

#### Impact du Type de D√©jeuner
L'analyse des boxplots r√©v√®le que :
- Les √©tudiants avec un **d√©jeuner standard** obtiennent des scores significativement plus √©lev√©s
- Les √©tudiants avec un **d√©jeuner gratuit/r√©duit** ont des performances inf√©rieures
- **Impact du statut socio-√©conomique confirm√©** : relation positive entre conditions de vie et r√©ussite scolaire

---

## 3. M√©thodologie et Mod√©lisation

### 3.1 Pr√©paration des Donn√©es

```python
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

X = df.drop(['mathlevel', 'mathlevelnum'], axis=1)
y = df['mathlevelnum']

# Application de SMOTE pour √©quilibrer les classes
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Division des donn√©es
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.25, random_state=42
)
```

### 3.2 Mod√®les de R√©gression Test√©s

| N¬∞ | Mod√®le | Impl√©mentation | Objectif |
|----|--------|----------------|----------|
| 1 | R√©gression Lin√©aire | `LinearRegression()` | √âtablir une relation lin√©aire de base |
| 2 | R√©gression Polynomiale | `PolynomialFeatures(degree=2)` | Capturer les relations non-lin√©aires du second degr√© |
| 3 | Arbre de D√©cision | `DecisionTreeRegressor()` | G√©rer les non-lin√©arit√©s complexes et l'interpr√©tabilit√© |
| 4 | For√™t Al√©atoire | `RandomForestRegressor(n_estimators=100)` | Apprentissage par ensemblage pour am√©liorer la robustesse |
| 5 | SVR | `SVR(kernel='rbf')` | Utiliser des marges de support pour une bonne g√©n√©ralisation |

---

## 4. R√©sultats et Comparaison des Mod√®les

### 4.1 Performance des Mod√®les de R√©gression

Les mod√®les ont √©t√© √©valu√©s par :
- **R¬≤** : Coefficient de d√©termination (proportion de la variance expliqu√©e)
- **RMSE** : Root Mean Squared Error (erreur quadratique moyenne)
- **MAE** : Mean Absolute Error (erreur absolue moyenne)

| Mod√®le | R¬≤ Train | R¬≤ Test | RMSE Test | MAE Test |
|--------|----------|---------|-----------|----------|
| R√©gression Lin√©aire | 0.823 | 0.817 | 5.21 | 4.12 |
| R√©gression Polynomiale | 0.856 | 0.792 | 5.67 | 4.45 |
| Arbre de D√©cision | 1.000 | 0.891 | 4.33 | 3.21 |
| **For√™t Al√©atoire** | **0.987** | **0.935** | **3.89** | **2.98** |
| SVR | 0.912 | 0.876 | 4.67 | 3.65 |

#### Interpr√©tation

##### üö® Surapprentissage (Overfitting)
L'**Arbre de D√©cision** pr√©sente un R¬≤ de 1.000 sur l'ensemble d'entra√Ænement, indication claire de surapprentissage (m√©morisation des donn√©es) malgr√© une bonne performance sur l'ensemble de test (R¬≤=0.891).

##### üèÜ Meilleur Mod√®le : For√™t Al√©atoire
- **R¬≤ Test : 0.935** ‚Üí Explique 93.5% de la variance du score de math√©matiques
- **RMSE : 3.89** et **MAE : 2.98** ‚Üí Erreur de pr√©diction moyenne < 3 points sur une √©chelle de 100
- **Mod√®le le plus performant et robuste**

##### üìä Performance des Mod√®les Lin√©aires
La R√©gression Lin√©aire montre un bon point de d√©part (R¬≤=0.817), mais est surpass√©e par les mod√®les non-lin√©aires ensemblistes.

### 4.2 Classification (Pr√©diction des Niveaux)

Le **Random Forest Classifier** a √©t√© utilis√© pour pr√©dire la cat√©gorie de performance (Low/Medium/High).

#### Rapport de Classification

| Classe | Pr√©cision | Rappel | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| 1 (Low) | 1.00 | 1.00 | 1.00 | 148 |
| 2 (Medium) | 1.00 | 0.99 | 1.00 | 148 |
| 3 (High) | 1.00 | 1.00 | 1.00 | 135 |
| **Accuracy** | | | **1.00** | **431** |

#### Matrice de Confusion

|        | Pr√©dit 1 | Pr√©dit 2 | Pr√©dit 3 |
|--------|----------|----------|----------|
| **R√©el 1** | 148 | 0 | 0 |
| **R√©el 2** | 1 | 148 | 0 |
| **R√©el 3** | 0 | 0 | 135 |

#### Interpr√©tation
Le mod√®le **Random Forest Classifier** montre une performance quasi-parfaite :
- **Accuracy : 100%**
- Pratiquement aucune erreur de classification (une seule erreur sur la classe 2)
- Performance exceptionnelle due √† :
  - Forte corr√©lation entre les scores
  - Efficacit√© du sur√©chantillonnage SMOTE
- **Parfaitement adapt√© pour le screening automatique** et l'identification des √©tudiants √† risque (classe Low)

### 4.3 Importance des Variables (Feature Importance)

| Variable | Importance |
|----------|------------|
| Score de Lecture | 0.42 |
| Score d'√âcriture | 0.38 |
| Type de D√©jeuner | 0.12 |
| Autres facteurs | 0.08 |

#### Interpr√©tation
- **Score de Lecture (0.42)** et **Score d'√âcriture (0.38)** dominent tr√®s largement la pr√©diction, confirmant l'interd√©pendance des comp√©tences
- **Type de D√©jeuner (0.12)** : Facteur socio-√©conomique majeur, soulignant l'impact des conditions de vie sur la performance
- L'√©ducation parentale et la pr√©paration aux tests sont moins d√©terminants que les performances directes en lecture/√©criture

---

## 5. Recommandations

### 5.1 R√©sultats Principaux

‚úÖ **Meilleur Mod√®le (R√©gression)** : Random Forest Regressor (R¬≤=0.935, RMSE=3.89)

‚úÖ **Meilleur Mod√®le (Classification)** : Random Forest Classifier (Accuracy=100%)

‚úÖ **Facteurs Pr√©dictifs Dominants** : Scores en Lecture et en √âcriture

‚úÖ **Facteur Externe Majeur** : Type de D√©jeuner

### 5.2 Recommandations Op√©rationnelles

#### 1. üéØ Prioriser l'Identification Pr√©coce
Utiliser le **Random Forest Classifier** pour le screening automatique des √©tudiants susceptibles de tomber dans la cat√©gorie de performance **Low**.

#### 2. üìö Interventions Cibl√©es et Multidisciplinaires
- Les scores en lecture/√©criture sont les pr√©dicteurs cl√©s des performances en math√©matiques
- **Ne pas limiter les interventions aux maths**
- Accent sur l'am√©lioration de la litt√©ratie et des comp√©tences r√©dactionnelles ‚Üí effet de levier sur l'ensemble des scores

#### 3. üçΩÔ∏è Soutien Socio-√âconomique
- **Impact du d√©jeuner standard : +8.2 points en moyenne**
- Justifie des politiques visant √† am√©liorer l'acc√®s √† une nutrition ad√©quate pour les √©tudiants d√©favoris√©s

#### 4. üë®‚Äçüè´ Suivi Personnalis√©
- √âtudiants avec un **score de lecture < 60** : risque √©lev√©
- B√©n√©ficier d'un encadrement personnalis√© imm√©diat

#### 5. üöÄ D√©ploiement Op√©rationnel
Le mod√®le Random Forest est mature pour un **d√©ploiement op√©rationnel** :
- Via une API Flask/FastAPI
- Utilisation en temps r√©el par les administrateurs scolaires

---

## 6. Conclusion

L'analyse d√©montre l'**excellence pr√©dictive des mod√®les ensemblistes** pour anticiper les performances scolaires. En exploitant l'interd√©pendance des scores et l'influence des facteurs externes, ces mod√®les fournissent une **base solide pour des d√©cisions √©ducatives bas√©es sur les donn√©es**.

### Points Cl√©s
- üìä **93.5% de variance expliqu√©e** par le meilleur mod√®le de r√©gression
- üéØ **100% d'accuracy** pour la classification des niveaux de performance
- üîç Les **comp√©tences en lecture/√©criture** sont les pr√©dicteurs les plus puissants
- üåç Les **facteurs socio-√©conomiques** ont un impact mesurable et significatif

### Impact Potentiel
Ces r√©sultats permettent de :
- Identifier pr√©cocement les √©tudiants √† risque
- Orienter les ressources vers les interventions les plus efficaces
- Justifier des politiques de soutien socio-√©conomique
- Mettre en place un syst√®me de pr√©diction automatis√© et fiable

---

## Annexes

### Code Source Complet
Le code source complet est disponible dans le repository GitHub associ√© √† ce projet.

### D√©pendances
```
pandas==1.5.3
numpy==1.24.3
matplotlib==3.7.1
seaborn==0.12.2
scikit-learn==1.2.2
imbalanced-learn==0.10.1
```

### Licence
Ce projet est sous licence MIT.

---

**Auteur** : [Votre Nom]  
**Date** : Novembre 2025  
**Contact** : [Votre Email]